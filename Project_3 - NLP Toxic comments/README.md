### Yandex.Practicum-Data-Science
# Определение токсичности комментариев (Обучение модели классификации комментариев)
## Описание проекта
Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Требуется инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.

## Описание данных
Данные находятся в файле toxic_comments.csv.
Столбец text в нём содержит текст комментария, а toxic — целевой признак.

## Используемые инструменты
`BERT` `spacy` `pymystem3` `re` `sklearn` `pandas` `numpy` `matplotlib` `plotly` `math` `Python` `nltk` `tf-idf`

# Модели
`BERT` `LogisticRegression` `RandomForestClassifier` `LightGBM` `DecisionTreeClassifier`

# Дополнительно
`TfidfVectorizer` `Lemmatizer` `GridSearchCV` `nltk` `tf-idf`

# Метрики
`f1_score`

### Основные шаги и выводы:
* Анализ данных, подготовка
* Токенизация, очистка и лемматизация данных
* Сравнение нескольких моделей
* Достижение требуемой метрики заказчика
* Выводы
